{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data from file\n",
    "The `trial_classes.xlsx` file has been enriched with additional multiclass labels identifying some characteristics of the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'data'\n",
    "\n",
    "data_dict = {}\n",
    "for file_name in os.listdir(data_directory):\n",
    "    file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    name = file_name.split('.')[0]\n",
    "    if file_type == 'parquet':\n",
    "        data_dict[name] = pd.read_parquet(file_path)\n",
    "    elif file_type == 'xlsx':\n",
    "        data_dict[name] = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_dict['country']\n",
    "\n",
    "# Drop columns with more than 90 % nans\n",
    "threshold = 0.9\n",
    "df = df.dropna(thresh=len(df) * (1 - threshold), axis=1)\n",
    "\n",
    "data_dict['country'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_dict['target']\n",
    "\n",
    "# Calculate target variable\n",
    "efficiency = df['no_of_patients'] / df['enrolment_months']\n",
    "df['efficiency'] = efficiency\n",
    "\n",
    "# Drop rows with nan target value\n",
    "df = df.dropna(subset=['efficiency'])\n",
    "\n",
    "# Drop rows with low time spent gathering patients\n",
    "# We make an arbitrary choice for a lower bound\n",
    "df = df[df['enrolment_months'] >= 0.1]\n",
    "\n",
    "data_dict['target'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_dict['trial_classes']\n",
    "\n",
    "# One hot encode trial phase\n",
    "df_ohe = pd.get_dummies(df['trial_phase'], drop_first=True)\n",
    "df_ohe = df_ohe.astype(int)\n",
    "df['trial_phase_III'] = df_ohe\n",
    "\n",
    "data_dict['trial_classes'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_dict['trial_site']\n",
    "\n",
    "df['site_start_date'] = pd.to_datetime(df['site_start_date'])\n",
    "df['site_end_date'] = pd.to_datetime(df['site_end_date'])\n",
    "df['trial_duration_days'] = (df['site_end_date'] - df['site_start_date']).dt.days\n",
    "\n",
    "data_dict['trial_site'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(data_dict['trial_site'], data_dict['country'], on='country_id', how='left')\n",
    "df = pd.merge(df, data_dict['trial_classes'], on='trial_id', how='left')\n",
    "df = pd.merge(df, data_dict['target'], on=['trial_id', 'site_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Make a smaller dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['site_type', 'trial_duration_days', 'nn_region',\n",
    "       'population', 'oecd_pharma_expenditure_per_capita',\n",
    "       'oecd_medical_grads_per_1k', 'oecd_MDs_per_1k',\n",
    "       'oecd_hospital_beds_per_1k', 'oecd_MR_units_per_1m',\n",
    "       'oecd_pte_units_total', 'oecd_hypnotics_sedatives_per_1k',\n",
    "       'oecd_antidepressants_per_1k', 'oecd_nervous_system_drugs_per_1k',\n",
    "       'oecd_perc_pop_insured_by_gov_health',\n",
    "       'oecd_perc_pop_insured_by_priv_health',\n",
    "       'oecd_perc_pop_insured_by_priv_or_gov_health',\n",
    "       'wb_diabetes_prevalence_perc_pop_age_20_to_79',\n",
    "       'who_gho_ncd_paa_prev_insuff_physical_activity',\n",
    "       'who_gho_ncd_paa_prev_insuff_physical_activity_male',\n",
    "       'who_gho_ncd_paa_prev_insuff_physical_activity_female',\n",
    "       'who_gho_mh_4_gov_exp_on_mental_perc_of_total_health',\n",
    "       'who_gho_mh_12_suicide_rate_per100k',\n",
    "       'who_gho_mh_16_beds_in_mental_hospitals_100k',\n",
    "       'who_gho_mh_13_beds_for_mental_in_gen_hospitals_100k',\n",
    "       'who_gho_gdo_q35_est_pop_prev_depression',\n",
    "       'who_gho_whosis_000001_life_expec_at_birth_w',\n",
    "       'who_gho_NCD_BMI_30A_obesity_prevalence_adults',\n",
    "       'who_gho_ghed_oopsche_sha2011_oop_expenditure_pct_current_health_expenditure',\n",
    "       'who_gho_ghed_che_pc_us_sha2011_curr_health_exp_per_capita_usd',\n",
    "       'who_gho_ghed_che_pc_ppp_sha2011_curr_health_exp_per_capita_ppp',\n",
    "       'who_gho_ghed_chegdp_sha2011_curr_health_exp_perc_gdp',\n",
    "       'who_gho_sdgpm25_pm25_concentration_val',\n",
    "       'who_gho_air_90_air_pollution_dalys_val',\n",
    "       'who_gho_hwf_0025_prc_female_medical_doctors', 'minimum_age',\n",
    "       'is_novo_nordisk_trial', 'is_top_20_sponsor', 'Heart Failure',\n",
    "       'Cardiovascular Stability', 'High Consent Emphasis',\n",
    "       'Technology-Enabled Monitoring', 'Weight Monitoring',\n",
    "       'Medication and Treatment History', 'Kidney Function',\n",
    "       'Cardiovascular Events', 'trial_phase_III', 'no_of_patients',\n",
    "       'enrolment_months', 'efficiency']\n",
    "\n",
    "df_training = df[keep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to be able to clean out `NaN` values but after clearing rows with any `NaN`s 89 rows remain so this is not feasible. Similarly, if we do it on columns we only get 14 columns left. We need to do something smarter.\n",
    "\n",
    "We elect to use a random forest as an initial machine learning approach as it is robust against missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict = {'full': df, 'training': df_training}\n",
    "for key, df in dfs_dict.items():\n",
    "    df.to_csv(f'data/{key}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Profile datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfs_dict.items():\n",
    "    prof = ProfileReport(df)\n",
    "    prof.to_file(output_file=f'profiles/{key}.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
