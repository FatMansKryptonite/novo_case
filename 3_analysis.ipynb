{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training.csv', index_col=0)\n",
    "categorical_cols = ['site_type', 'nn_region', 'is_novo_nordisk_trial', 'is_top_20_sponsor', 'Heart Failure',\n",
    "       'Cardiovascular Stability', 'High Consent Emphasis',\n",
    "       'Technology-Enabled Monitoring', 'Weight Monitoring',\n",
    "       'Medication and Treatment History', 'Kidney Function',\n",
    "       'Cardiovascular Events', 'trial_phase_III']\n",
    "numerical_cols = list(set(df.columns) - set(categorical_cols) - {'efficiency'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Drop rows that still have NaNs (missing efficiency)\n",
    "df = df.dropna(subset=['efficiency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=2)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "\n",
    "# Splitting the data\n",
    "df = df.dropna(subset=['efficiency'])\n",
    "X = df.drop('efficiency', axis=1)\n",
    "y = df['efficiency']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Preprocessing of training data, fit model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "print(\"Model training complete. You can now make predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    nonzero = y_true != 0\n",
    "    return np.mean(np.abs((y_true[nonzero] - y_pred[nonzero]) / y_true[nonzero])) * 100\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating MSE\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(f'Mean Squared Training Error: {mse_train:.3f}')\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Mean Squared Testing Error: {mse_test:.3f}')\n",
    "\n",
    "# Calculate MAPE\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "print(f'Mean Absolute Percentage Training Error: {mape_train:.3f} %')\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "print(f'Mean Absolute Percentage Testing Error: {mape_test:.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_train\n",
    "y_pred = y_train_pred\n",
    "\n",
    "total = 0\n",
    "for i, (true, pred) in enumerate(zip(y_true, y_pred)):\n",
    "    squared_error = (true - pred)**2\n",
    "    total += squared_error\n",
    "\n",
    "    if squared_error > 10:\n",
    "        print(f'{i}: True: {true}, Predicted: {pred}, Squared Error: {squared_error}')\n",
    "\n",
    "print(f'Total squared error: {total}, MSE: {total / len(y_true)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
